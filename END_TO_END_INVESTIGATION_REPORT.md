# üîç END-TO-END INVESTIGATION REPORT
## Lekhika Engine Execution Issues - Complete Analysis

**Date:** 2025-11-20  
**Engine Tested:** Novella  
**Issues Reported:** 5 Critical Issues  
**Status:** Investigation Complete - NO CODE CHANGES MADE

---

## üìã EXECUTIVE SUMMARY

After running the Novella engine, 5 critical issues were identified:
1. **Tokens not deducted** (12k tokens used, wallet unchanged)
2. **HTML format not downloaded**
3. **PDF quality is poor** (dog shit formatting)
4. **AI Thinking Modal shows 0 tokens** for Content Writer nodes
5. **TOC is wrong** (placeholder names, wrong chapter count, formatting issues)

**Root Cause Analysis:** Multiple disconnected data flows and missing token aggregation points.

---

## üî¥ ISSUE #1: TOKENS NOT BEING DEDUCTED

### **Problem Statement**
- User used 12,000 tokens during execution
- Wallet balance did not change
- Tokens were not debited from user account

### **Investigation Findings**

#### **Token Flow Architecture:**

1. **Token Recording (During Execution):**
   - Location: `vps-worker/services/workflowExecutionService.js:479`
   - Method: `recordNodeTokenUsage(workflowId, nodeMeta, nodeOutput)`
   - Called after each node execution completes
   - Stores token data in `stateManager.executionState[workflowId].tokenUsage` and `tokenLedger`

2. **Token Aggregation (End of Workflow):**
   - Location: `vps-worker/services/workflowExecutionService.js:693-700`
   - Method: `getTokenUsageSummaryHelper(stateManager, workflowId, pipelineData.nodeOutputs)`
   - Returns: `{ totalTokens, totalCost, totalWords }`
   - Sets: `pipelineData.totalTokensUsed = finalTokenUsage.totalTokens`

3. **Token Deduction (executionService.js):**
   - Location: `vps-worker/services/executionService.js:725-817`
   - **PROBLEM IDENTIFIED HERE:**
   - Line 725: `let totalTokensUsed = result?.totalTokensUsed || result?.tokenUsage?.debited || 0`
   - Line 730-755: Falls back to calculating from `result.nodeOutputs` by iterating and summing `aiMetadata.tokens`
   - Line 777: **ONLY DEBITS IF `totalTokensUsed > 0`**

### **Root Cause Analysis:**

**PRIMARY ISSUE:** Token data flow breakage between `workflowExecutionService` and `executionService`:

1. **Missing Token Data in nodeOutputs:**
   - `contentGenerationHandler.js` sets `aiMetadata.tokens` correctly (line 456)
   - But `recordNodeTokenUsage` stores tokens in `stateManager.executionState[workflowId]`
   - `executionService.js` line 730-755 looks for tokens in `result.nodeOutputs[nodeId].aiMetadata.tokens`
   - **IF** `nodeOutputs` don't have `aiMetadata.tokens` populated, calculation returns 0

2. **Fallback Logic Failure:**
   - `executionService.js` line 758-762: If `totalTokensUsed === 0`, it tries to read from `result.totalTokensUsed`
   - But if `getTokenUsageSummaryHelper` returns `{ totalTokens: 0 }` (because state is empty or nodeOutputs don't have tokens), the fallback also fails

3. **State vs Outputs Mismatch:**
   - Tokens are stored in `stateManager.executionState[workflowId].tokenUsage` (via `recordNodeTokenUsage`)
   - But `executionService.js` doesn't access `stateManager` - it only looks at `result.nodeOutputs`
   - `getTokenUsageSummaryHelper` checks state first, then falls back to nodeOutputs
   - **IF** state is cleared or not persisted, and nodeOutputs don't have tokens, total = 0

### **Evidence:**

```javascript
// workflowExecutionService.js:693-700
const finalTokenUsage = getTokenUsageSummaryHelper(stateManager, workflowId, pipelineData.nodeOutputs)
pipelineData.totalTokensUsed = finalTokenUsage.totalTokens  // ‚úÖ Sets this

// executionService.js:725
let totalTokensUsed = result?.totalTokensUsed || result?.tokenUsage?.debited || 0  // ‚úÖ Should get it here

// BUT executionService.js:730-755
// Tries to recalculate from nodeOutputs if totalTokensUsed is 0 or missing
// This suggests the value might not be passed correctly
```

### **Why It Worked Before Refactoring:**
- Previously, tokens were stored directly in `nodeOutputs` as part of the class state
- After refactoring, tokens are stored in `stateManager` but might not be properly copied to `nodeOutputs`
- `recordNodeTokenUsage` stores in state, but doesn't ensure `nodeOutputs[nodeId].aiMetadata.tokens` is set

### **Solution Required:**
1. Ensure `recordNodeTokenUsage` also populates `nodeOutput.aiMetadata.tokens` directly
2. OR ensure `getTokenUsageSummaryHelper` always returns correct totals from state
3. OR ensure `executionService.js` reads from `result.totalTokensUsed` correctly (verify the value is actually set)

---

## üî¥ ISSUE #2: HTML FORMAT NOT DOWNLOADED

### **Problem Statement**
- User selected 5 formats including HTML
- HTML file was not available for download
- Other formats (MD, TXT, PDF, DOCX) were available

### **Investigation Findings**

#### **HTML Generation Flow:**

1. **Format Selection:**
   - Location: `vps-worker/services/workflow/handlers/outputHandler.js:50-90`
   - User formats come from `pipelineData.userInput.output_formats` or `exportFormats`
   - Final formats: `finalExportFormats = userInputFormats || nodeFormats || [outputFormat || 'markdown']`

2. **Format Generation:**
   - Location: `vps-worker/services/workflow/helpers/outputHelpers.js:72-293`
   - Line 79-82: **HTML is ALWAYS added** if not present: `if (!formatsToGenerate.includes('html')) { formatsToGenerate = ['html', ...formatsToGenerate] }`
   - Line 91-277: Loops through `formatsToGenerate` and generates each format

3. **HTML Format Generation:**
   - Location: `vps-worker/services/workflow/helpers/outputHelpers.js:262-266`
   - HTML is a **text format** (not binary like PDF/DOCX)
   - Uses `professionalBookFormatter.formatCompleteBook(compiledContent, userInput, 'html', ...)`
   - Result stored in `formattedOutputs['html']`

4. **Deliverable Generation:**
   - Location: `vps-worker/services/workflow/helpers/outputHelpers.js:304-393`
   - Line 308-362: Iterates through `formattedOutput.allFormats`
   - Creates deliverable objects with `format`, `content`, `filename`, `mimeType`

### **Root Cause Analysis:**

**PRIMARY ISSUE:** HTML might be generated but not included in deliverables OR not passed to frontend correctly.

**Possible Causes:**

1. **Format Name Case Sensitivity:**
   - Line 79 checks: `!formatsToGenerate.includes('html')`
   - If user selected `'HTML'` (uppercase), it might not match
   - Line 93: `const formatStr = typeof format === 'string' ? format : String(format)`
   - But the check at line 79 is case-sensitive

2. **Deliverable Filtering:**
   - `generateDeliverables` iterates `formattedOutput.allFormats`
   - If `allFormats` doesn't have `'html'` key (maybe it's `'HTML'`), it won't create a deliverable

3. **Frontend Download Logic:**
   - Need to check if frontend filters out HTML or expects a different format name
   - If frontend expects `'html'` but backend sends `'HTML'`, download might fail silently

### **Evidence:**

```javascript
// outputHelpers.js:79-82
if (!formatsToGenerate.includes('html') && !formatsToGenerate.includes('HTML')) {
  formatsToGenerate = ['html', ...formatsToGenerate]  // ‚úÖ Adds lowercase 'html'
}

// outputHelpers.js:310
Object.entries(formattedOutput.allFormats).forEach(([format, content]) => {
  // Creates deliverable for each format in allFormats
  // If format key is 'HTML' but frontend expects 'html', mismatch occurs
})
```

### **Solution Required:**
1. Normalize format names to lowercase before processing
2. Ensure HTML is always included in `allFormats` with key `'html'`
3. Verify frontend download logic accepts `'html'` format
4. Add logging to verify HTML deliverable is created and passed to frontend

---

## üî¥ ISSUE #3: PDF QUALITY IS POOR

### **Problem Statement**
- PDF format is generated but quality is "dog shit"
- Formatting is broken, hardcoded content appears
- User expects professional, clean PDF output

### **Investigation Findings**

#### **PDF Generation Flow:**

1. **Format Selection:**
   - Location: `vps-worker/services/workflow/helpers/outputHelpers.js:236-261`
   - PDF is treated as **binary format** (line 236: `if (['pdf', 'docx', 'epub'].includes(formatStr.toLowerCase()))`)

2. **Beautiful Content Generation:**
   - Location: `vps-worker/services/workflow/helpers/outputHelpers.js:228-233`
   - First generates "beautiful" HTML content using `professionalBookFormatter.formatCompleteBook()`
   - This creates properly formatted HTML with typography, structure, TOC, etc.

3. **PDF Conversion:**
   - Location: `vps-worker/services/workflow/helpers/outputHelpers.js:250-252`
   - Passes `enhancedData` to `exportService.generatePDF(enhancedData)`
   - `enhancedData` includes: `beautifulContent`, `typographyPrefs`, `sections`, `userInput`

4. **PDF Generation Implementation:**
   - Location: `vps-worker/services/exportService.js:898-1064`
   - Line 907-916: **Tries to extract chapters from `beautifulContent`** if available
   - Line 908: `const extracted = this.extractChaptersFromHTML(compiledContent.beautifulContent)`
   - Line 1070-1103: `extractChaptersFromHTML()` uses regex to parse HTML
   - **PROBLEM:** Regex-based extraction is fragile and might miss content

### **Root Cause Analysis:**

**PRIMARY ISSUE:** PDF generation doesn't properly use the beautiful formatted content.

**Specific Problems:**

1. **HTML Extraction is Fragile:**
   - `extractChaptersFromHTML()` uses regex: `/<div class="chapter">(.*?)<\/div>/gs`
   - If `professionalBookFormatter` uses different HTML structure, extraction fails
   - Falls back to stripping all HTML tags, losing formatting

2. **Hardcoded Content:**
   - Line 923-926 in `professionalBookFormatter.js`:
   ```javascript
   return (chapters || []).map((chapter, index) => ({
     label: `Chapter ${chapter.chapter || index + 1}: ${chapter.title || `Chapter ${chapter.chapter || index + 1}`}`,
     chapter: chapter.chapter || index + 1
   }))
   ```
   - If `chapter.title` is missing, uses placeholder `Chapter ${index + 1}`
   - This explains the "Content Writer" placeholder in TOC

3. **PDF Doesn't Use Beautiful Content:**
   - `exportService.generatePDF()` receives `beautifulContent` but might not use it properly
   - Might be generating PDF from raw `sections` instead of formatted HTML

4. **Typography Not Applied:**
   - `typographyPrefs` are passed but PDF generation might not apply them
   - PDF uses default fonts/sizes instead of user preferences

### **Evidence:**

```javascript
// exportService.js:907-916
if (compiledContent.beautifulContent && compiledContent.typographyPrefs) {
  const extracted = this.extractChaptersFromHTML(compiledContent.beautifulContent)
  // ‚úÖ Tries to use beautiful content
  // ‚ùå But extraction is regex-based and fragile
}

// professionalBookFormatter.js:923-926
return (chapters || []).map((chapter, index) => ({
  label: `Chapter ${chapter.chapter || index + 1}: ${chapter.title || `Chapter ${chapter.chapter || index + 1}`}`,
  // ‚ùå Fallback to placeholder if title is missing
}))
```

### **Solution Required:**
1. Fix `extractChaptersFromHTML()` to properly parse HTML structure from `professionalBookFormatter`
2. Ensure PDF uses `beautifulContent` directly instead of re-extracting
3. Apply `typographyPrefs` to PDF generation (fonts, sizes, margins)
4. Fix TOC generation to use actual chapter titles, not placeholders
5. Remove hardcoded fallbacks - fail if data is missing instead of using placeholders

---

## üî¥ ISSUE #4: AI THINKING MODAL SHOWS 0 TOKENS

### **Problem Statement**
- AI Thinking Modal UI shows "0 tokens" for Content Writer nodes
- Story Architect shows 2339 tokens correctly
- Other nodes show 0 tokens

### **Investigation Findings**

#### **Token Display Flow:**

1. **Frontend Token Reading:**
   - Location: `src/components/AIThinkingModal.jsx:1277`
   - Reads: `tokens: result.tokens || result.aiMetadata?.tokens || 0`
   - Also reads from live updates: `liveOutput.tokens || 0` (line 1195)

2. **Backend Token Storage:**
   - Location: `vps-worker/services/workflow/handlers/contentGenerationHandler.js:452-463`
   - Sets: `aiMetadata: { tokens: actualTokens, cost: actualCost, words: actualWordCount }`
   - Also sets: `tokens: actualTokens` (line 463) at root level

3. **Progress Callback:**
   - Location: `vps-worker/services/workflow/handlers/contentGenerationHandler.js:681-698`
   - Sends: `tokens: chapterResult.aiMetadata?.tokens || 0`
   - This is sent via `progressCallback` to frontend

### **Root Cause Analysis:**

**PRIMARY ISSUE:** Token data is not being passed correctly in progress callbacks or final results.

**Specific Problems:**

1. **Progress Callback Token Data:**
   - `contentGenerationHandler.js:689`: `tokens: chapterResult.aiMetadata?.tokens || 0`
   - If `chapterResult.aiMetadata` is missing, shows 0
   - For multi-chapter generation, tokens might be aggregated at the end, not per chapter

2. **Final Result Token Data:**
   - `contentGenerationHandler.js:452-463`: Sets `aiMetadata.tokens` and `tokens` at root
   - But this is for single generation
   - For multi-chapter, tokens are aggregated in `aiMetadata.totalTokens` (line 745)
   - Frontend might be reading `result.tokens` (single) instead of `result.aiMetadata.totalTokens` (aggregated)

3. **Node Output Decoration:**
   - `workflowExecutionService.js:469-477`: Decorates node output before storing
   - Might not preserve `aiMetadata.tokens` if it's nested

### **Evidence:**

```javascript
// contentGenerationHandler.js:452-463 (single generation)
aiMetadata: {
  tokens: actualTokens,  // ‚úÖ Set here
  cost: actualCost,
  words: actualWordCount
},
tokens: actualTokens,  // ‚úÖ Also at root

// contentGenerationHandler.js:741-746 (multi-chapter)
aiMetadata: {
  totalTokens: totalTokens,  // ‚úÖ Aggregated total
  totalCost: totalCost,
  totalWords: totalWords
}
// ‚ùå But no `tokens` at root level for multi-chapter

// AIThinkingModal.jsx:1277
tokens: result.tokens || result.aiMetadata?.tokens || 0
// ‚ùå For multi-chapter, should read `result.aiMetadata.totalTokens`
```

### **Solution Required:**
1. Ensure multi-chapter results also set `tokens` at root level (not just `aiMetadata.totalTokens`)
2. Update frontend to read `result.aiMetadata.totalTokens` for multi-chapter nodes
3. Ensure progress callbacks include token data for each chapter
4. Verify `recordNodeTokenUsage` doesn't strip token data from nodeOutputs

---

## üî¥ ISSUE #5: TOC IS WRONG (PLACEHOLDER NAMES, WRONG COUNT)

### **Problem Statement**
- TOC shows "Chapter 1: Content Writer" (placeholder)
- Book has 4 chapters but TOC shows 5 entries
- Formatting is broken

### **Investigation Findings**

#### **TOC Generation Flow:**

1. **TOC Source Priority:**
   - Location: `vps-worker/services/professionalBookFormatter.js:901-927`
   - Priority 1: `structural.tableOfContentsList` (array from Story Architect)
   - Priority 2: `structural.tableOfContents` (string from Story Architect)
   - Priority 3: **Fallback to chapters** (line 923-926)

2. **Chapter Title Extraction:**
   - Location: `vps-worker/services/workflow/contentCompiler.js:290-312`
   - For multi-chapter: Uses `chapter.title` from `output.content` array
   - For single content: Uses `extractChapterStructure()` to parse title from content

3. **TOC Fallback Logic:**
   - Location: `vps-worker/services/professionalBookFormatter.js:923-926`
   ```javascript
   return (chapters || []).map((chapter, index) => ({
     label: `Chapter ${chapter.chapter || index + 1}: ${chapter.title || `Chapter ${chapter.chapter || index + 1}`}`,
     chapter: chapter.chapter || index + 1
   }))
   ```
   - **PROBLEM:** If `chapter.title` is missing, uses placeholder

4. **Chapter Title Population:**
   - Location: `vps-worker/services/workflow/contentCompiler.js:304-311`
   - Sets: `title: chapter.title || `Chapter ${chNum}``
   - If `chapter.title` is not set by content generation, uses placeholder

### **Root Cause Analysis:**

**PRIMARY ISSUE:** Chapter titles are not being extracted/populated correctly, causing TOC to use placeholders.

**Specific Problems:**

1. **Missing Chapter Titles:**
   - `contentGenerationHandler.js` generates chapters but might not set `chapter.title`
   - `contentCompiler.js` uses `chapter.title || `Chapter ${chNum}``
   - If title is missing, TOC uses placeholder

2. **TOC Fallback Uses Placeholder:**
   - `professionalBookFormatter.js:924`: `chapter.title || `Chapter ${chapter.chapter || index + 1}``
   - If title is missing, creates "Chapter 1: Chapter 1" or "Chapter 1: Content Writer" (from node name)

3. **Wrong Chapter Count:**
   - TOC shows 5 chapters but book has 4
   - Might be counting structural elements (Foreword, Introduction) as chapters
   - OR TOC is generated from wrong source (old data, wrong node outputs)

4. **Content Writer Placeholder:**
   - "Content Writer" is the **node name**, not the chapter title
   - Suggests TOC is using `nodeName` or `nodeLabel` instead of actual chapter title

### **Evidence:**

```javascript
// professionalBookFormatter.js:923-926
return (chapters || []).map((chapter, index) => ({
  label: `Chapter ${chapter.chapter || index + 1}: ${chapter.title || `Chapter ${chapter.chapter || index + 1}`}`,
  // ‚ùå If title is missing, uses placeholder
}))

// contentCompiler.js:304-311
content.sections.push({
  title: chapter.title || `Chapter ${chNum}`,  // ‚ùå Placeholder if missing
  chapterNumber: chNum,
  content: chapter.content,
})
```

### **Solution Required:**
1. Ensure `contentGenerationHandler` extracts and sets `chapter.title` from generated content
2. Use `extractChapterTitle()` helper to parse titles from content if not provided
3. Fix TOC to use actual chapter titles, not node names or placeholders
4. Ensure TOC count matches actual chapter count (exclude structural elements from count)
5. Verify TOC source (should use `structural.tableOfContentsList` from Story Architect if available)

---

## üîó INTERCONNECTED ISSUES

### **Single Source of Truth Violation:**

All 5 issues stem from **multiple sources of truth** for the same data:

1. **Tokens:** Stored in `stateManager`, `nodeOutputs.aiMetadata`, `result.totalTokensUsed`, `executionService` calculations
2. **Content:** Stored in `nodeOutputs`, `compiledContent.sections`, `beautifulContent`, `formattedOutputs`
3. **TOC:** Stored in `structural.tableOfContentsList`, `structural.tableOfContents`, derived from `chapters`
4. **Formats:** Stored in `formattedOutputs.allFormats`, `deliverables`, frontend expectations

### **Data Flow Gaps:**

1. **State ‚Üí Outputs:** `stateManager` stores tokens but `nodeOutputs` might not have them
2. **Compiled ‚Üí Formatted:** `compiledContent` has correct data but `formattedOutputs` might use wrong source
3. **Backend ‚Üí Frontend:** Backend sends data but frontend might read from wrong location

---

## ‚úÖ RECOMMENDED SOLUTIONS

### **Priority 1: Token Deduction (Critical)**
1. Ensure `recordNodeTokenUsage` populates `nodeOutput.aiMetadata.tokens` directly
2. Verify `getTokenUsageSummaryHelper` reads from state correctly
3. Ensure `executionService.js` uses `result.totalTokensUsed` (don't recalculate if already set)
4. Add logging to track token flow: state ‚Üí nodeOutputs ‚Üí result ‚Üí deduction

### **Priority 2: HTML Download (High)**
1. Normalize format names to lowercase before processing
2. Ensure HTML is always in `allFormats` with key `'html'`
3. Verify frontend download logic
4. Add logging to verify HTML deliverable creation

### **Priority 3: PDF Quality (High)**
1. Fix `extractChaptersFromHTML()` to properly parse HTML structure
2. Use `beautifulContent` directly in PDF (don't re-extract)
3. Apply `typographyPrefs` to PDF generation
4. Remove hardcoded placeholders - fail if data is missing

### **Priority 4: Token Display (Medium)**
1. Ensure multi-chapter results set `tokens` at root level
2. Update frontend to read `aiMetadata.totalTokens` for multi-chapter
3. Ensure progress callbacks include token data

### **Priority 5: TOC Fix (Medium)**
1. Extract chapter titles from content if not provided
2. Use actual titles, not node names or placeholders
3. Ensure TOC count matches chapter count
4. Use `structural.tableOfContentsList` if available (from Story Architect)

---

## üìä TESTING CHECKLIST

After fixes are implemented, verify:

- [ ] Tokens are deducted from wallet after execution
- [ ] Token deduction amount matches AI Thinking Modal total
- [ ] HTML format is available for download
- [ ] PDF has proper formatting, typography, and structure
- [ ] PDF TOC matches actual chapters with correct titles
- [ ] AI Thinking Modal shows correct token counts for all nodes
- [ ] TOC shows correct chapter count and titles (no placeholders)
- [ ] All formats (HTML, PDF, DOCX, MD, TXT) have consistent content
- [ ] Single source of truth: same content in all formats and locations

---

## üéØ SUCCESS CRITERIA

1. **Token Deduction:** Wallet balance decreases by exact amount used
2. **HTML Download:** HTML file is available and downloadable
3. **PDF Quality:** Professional formatting, correct TOC, proper typography
4. **Token Display:** AI Thinking Modal shows accurate token counts
5. **TOC Accuracy:** Correct chapter count, actual titles (no placeholders)
6. **Single Source of Truth:** Same content/structure across all formats and UI locations

---

**END OF REPORT**


