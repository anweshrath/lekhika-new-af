// AI API Validation Service - CORS-free implementation
class AIValidationService {
  constructor() {
    this.validationCache = new Map()
    this.modelCache = new Map()
  }

  // OpenAI API validation with dynamic model fetching
  async validateOpenAI(apiKey) {
    try {
      console.log('üîç Validating OpenAI API key...')
      
      // Test with a simple completion request to validate the key
      const testResponse = await fetch('/api/openai/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: 'gpt-3.5-turbo',
          messages: [{ role: 'user', content: 'Hi' }],
          max_tokens: 1
        })
      })

      if (!testResponse.ok) {
        const errorText = await testResponse.text()
        throw new Error(`HTTP ${testResponse.status}: ${testResponse.statusText} - ${errorText}`)
      }

      // Fetch available models dynamically from OpenAI's API
      const modelsResponse = await fetch('/api/openai/models', {
        method: 'GET',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        }
      })

      let models = []
      
      if (modelsResponse.ok) {
        const modelsData = await modelsResponse.json()
        models = modelsData.data
          ?.filter(model => 
          model.id.includes('gpt') || 
          model.id.includes('dall-e') || 
          model.id.includes('whisper') ||
          model.id.includes('tts')
        )
          ?.map(model => this.formatOpenAIModel(model))
          ?.sort((a, b) => a.name.localeCompare(b.name)) || []
      } else {
        // Fallback to known models if models endpoint fails
        console.log('‚ö†Ô∏è Models endpoint failed, using known OpenAI models')
        models = this.getKnownOpenAIModels()
      }

      console.log(`‚úÖ OpenAI validation successful - ${models.length} models found`)
      
      return {
        success: true,
        models,
        service: 'openai'
      }
    } catch (error) {
      console.error('‚ùå OpenAI validation failed:', error)
      return {
        success: false,
        error: error.message,
        models: []
      }
    }
  }

  getKnownOpenAIModels() {
    // Return empty array - no hardcoded models allowed
    return []
  }

  formatOpenAIModel(model) {
    const modelInfo = {
      id: model.id,
      name: model.id,
      contextSize: model.context_window || null,
      costPer1k: model.pricing?.input_cost_per_1k_tokens || null,
      capabilities: model.capabilities || [],
      description: model.description || null
    }
    return modelInfo
  }

  // Hardcoded context size function removed - only dynamic data allowed

  // Hardcoded cost function removed - only dynamic data allowed

  // Hardcoded capabilities function removed - only dynamic data allowed

  // Hardcoded description function removed - only dynamic data allowed

  // Parse model date from various sources
  parseModelDate(model, provider) {
    // Try different date field names based on provider
    const dateFields = {
      'claude': ['created_at', 'createdAt', 'creation_date'],
      'openai': ['created', 'created_at', 'creation_date'],
      'mistral': ['created', 'created_at', 'creation_timestamp'],
      'gemini': ['created_at', 'creation_date', 'updated_at'],
      'anthropic': ['created_at', 'createdAt']
    }

    const possibleFields = dateFields[provider] || ['created_at', 'created', 'creation_date', 'updated_at']

    for (const field of possibleFields) {
      if (model[field]) {
        return this.standardizeDate(model[field], provider)
      }
    }

    // Fallback: Extract from model ID/name patterns
    return this.extractDateFromModelId(model.id || model.name)
  }

  // Standardize date from various formats
  standardizeDate(rawDate, provider) {
    if (!rawDate) return null

    // Handle Unix timestamps (seconds)
    if (typeof rawDate === 'number' && rawDate > 1000000000 && rawDate < 2000000000) {
      return new Date(rawDate * 1000).toISOString()
    }

    // Handle Unix timestamps (milliseconds)
    if (typeof rawDate === 'number' && rawDate > 1000000000000) {
      return new Date(rawDate).toISOString()
    }

    // Handle ISO strings
    if (typeof rawDate === 'string') {
      const parsed = new Date(rawDate)
      if (!isNaN(parsed.getTime())) return parsed.toISOString()
    }

    return null
  }

  // Extract date from model ID patterns
  extractDateFromModelId(modelId) {
    if (!modelId) return null

    // Pattern: model-name-YYYYMMDD or model-name-v1.0-2024-06-20
    const datePatterns = [
      /(\d{4}-\d{2}-\d{2})/,           // 2024-06-20
      /(\d{4}\d{2}\d{2})/,             // 20240620
      /(\d{4}-\d{2})/,                 // 2024-06
      /v(\d+\.\d+)-(\d{4}-\d{2}-\d{2})/ // v1.0-2024-06-20
    ]

    for (const pattern of datePatterns) {
      const match = modelId.match(pattern)
      if (match) {
        const dateStr = match[1] || match[2]
        if (dateStr) {
          const parsed = new Date(dateStr)
          if (!isNaN(parsed.getTime())) return parsed.toISOString()
        }
      }
    }

    return null
  }

  // Claude API validation with dynamic model fetching
  async validateClaude(apiKey) {
    try {
      console.log('üîç Validating Claude API key...')
      
      // Test with a simple message to validate the key
      const testResponse = await fetch('/api/claude/messages', {
        method: 'POST',
        headers: {
          'x-api-key': apiKey,
          'Content-Type': 'application/json',
          'anthropic-version': '2023-06-01',
          'anthropic-dangerous-direct-browser-access': 'true'
        },
        body: JSON.stringify({
          model: 'claude-3-haiku-20240307',
          max_tokens: 1,
          messages: [{ role: 'user', content: 'Hi' }]
        })
      })

      if (!testResponse.ok) {
        const errorText = await testResponse.text()
        throw new Error(`HTTP ${testResponse.status}: ${testResponse.statusText} - ${errorText}`)
      }

      // Fetch available models dynamically from Claude's API
      const modelsResponse = await fetch('/api/claude/models', {
        method: 'GET',
        headers: {
          'x-api-key': apiKey,
          'Content-Type': 'application/json',
          'anthropic-version': '2023-06-01',
          'anthropic-dangerous-direct-browser-access': 'true'
        }
      })

      let models = []
      
      if (modelsResponse.ok) {
        const modelsData = await modelsResponse.json()
        models = modelsData.data?.map(model => ({
          id: model.id,
          name: model.name || model.id,
          contextSize: model.context_window || null,
          costPer1k: model.pricing?.input_cost_per_1k_tokens || null,
          capabilities: model.capabilities || [],
          description: model.description || null,
          conceptionDate: this.parseModelDate(model, 'claude')
        })) || []
      } else {
        // Fallback to known models if models endpoint fails
        console.log('‚ö†Ô∏è Models endpoint failed, using known Claude models')
        models = this.getKnownClaudeModels()
      }

      console.log(`‚úÖ Claude validation successful - ${models.length} models found`)
      
      return {
        success: true,
        models,
        service: 'anthropic'
      }
    } catch (error) {
      console.error('‚ùå Claude validation failed:', error)
      return {
        success: false,
        error: error.message,
        models: []
      }
    }
  }

  getClaudeContextSize(modelId) {
    // Return null - no hardcoded context sizes allowed
    return null
  }

  getClaudeCost(modelId) {
    // Return null - no hardcoded costs allowed
    return null
  }

  getClaudeCapabilities(modelId) {
    // Return empty array - no hardcoded capabilities allowed
    return []
  }

  getClaudeDescription(modelId) {
    // Return null - no hardcoded descriptions allowed
    return null
  }

  getKnownClaudeModels() {
    // Return empty array - no hardcoded models allowed
    return []
  }

  // Gemini API validation with proper OAuth and dynamic model fetching
  async validateGemini(apiKey) {
    try {
      console.log('üîç Validating Gemini API key...')
      
      // Fetch available models dynamically from Gemini's API FIRST
      const modelsResponse = await fetch(`/api/gemini/models?key=${apiKey}`, {
        method: 'GET',
        headers: {
          'Content-Type': 'application/json'
        }
      })

      let models = []
      let testModel = null
      
      if (modelsResponse.ok) {
        const modelsData = await modelsResponse.json()
        console.log('üîç Raw Gemini API response:', modelsData)
        console.log('üîç First Gemini model raw data:', modelsData.models?.[0])
        
        const availableModels = modelsData.models?.filter(model => 
          model.name.includes('gemini') && 
          model.supportedGenerationMethods?.includes('generateContent')
        ) || []
        
        if (availableModels.length === 0) {
          throw new Error('No compatible Gemini models found that support generateContent')
        }
        
        // Use the first available model for testing
        testModel = availableModels[0].name.split('/').pop()
        console.log(`üß™ Using model for validation test: ${testModel}`)
        
        models = availableModels.map(model => ({
          id: model.name.split('/').pop(),
          name: model.displayName || model.name.split('/').pop(),
          contextSize: model.inputTokenLimit || null,
          costPer1k: null, // Gemini doesn't provide pricing in models endpoint
          capabilities: model.supportedGenerationMethods || [],
          description: model.description || null,
          conceptionDate: this.parseModelDate(model, 'gemini'),
          rawModel: model // Store the raw model data for debugging
        })).sort((a, b) => a.name.localeCompare(b.name))
      } else {
        const errorText = await modelsResponse.text()
        throw new Error(`Failed to fetch Gemini models: HTTP ${modelsResponse.status} - ${errorText}`)
      }
      
      // Now test the API key with the dynamically discovered model
      const testResponse = await fetch(`/api/gemini/models/${testModel}:generateContent?key=${apiKey}`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          contents: [{
            parts: [{
              text: 'Hello'
            }]
          }],
          generationConfig: {
            maxOutputTokens: 1
          }
        })
      })

      if (!testResponse.ok) {
        const errorText = await testResponse.text()
        throw new Error(`API key validation failed: HTTP ${testResponse.status}: ${testResponse.statusText} - ${errorText}`)
      }

      console.log(`‚úÖ Gemini validation successful - ${models.length} models found`)
      
      return {
        success: true,
        models,
        service: 'gemini'
      }
    } catch (error) {
      console.error('‚ùå Gemini validation failed:', error)
      return {
        success: false,
        error: error.message,
        models: []
      }
    }
  }

  getKnownGeminiModels() {
    // Return empty array - no hardcoded models allowed
    return []
  }

  getGeminiContextSize(modelName) {
    // Return null - no hardcoded context sizes allowed
    return null
  }

  getGeminiCost(modelName) {
    // Return null - no hardcoded costs allowed
    return null
  }

  getGeminiCapabilities(modelName) {
    // Return empty array - no hardcoded capabilities allowed
    return []
  }

  // Mistral API validation
  async validateMistral(apiKey) {
    try {
      console.log('üîç Validating Mistral API key...')
      
      // Using Vite proxy to avoid CORS issues
      // Proxy route: /api/mistral/* -> https://api.mistral.ai/v1/*
      const response = await fetch('/api/mistral/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: 'mistral-small-latest',
          messages: [{ role: 'user', content: 'Hello' }],
          max_tokens: 5,
          temperature: 0.1
        })
      })

      if (!response.ok) {
        const errorText = await response.text()
        console.error('‚ùå Mistral API response:', {
          status: response.status,
          statusText: response.statusText,
          headers: Object.fromEntries(response.headers.entries()),
          body: errorText
        })
        
        // Provide more specific error messages
        if (response.status === 401) {
          throw new Error('Invalid API key. Please check your Mistral API key.')
        } else if (response.status === 403) {
          throw new Error('Access forbidden. Please check your API key permissions.')
        } else if (response.status === 429) {
          throw new Error('Rate limit exceeded. Please try again later.')
        } else if (response.status >= 500) {
          throw new Error('Mistral API server error. Please try again later.')
        } else {
          throw new Error(`API Error ${response.status}: ${errorText || response.statusText}`)
        }
      }

      // Fetch available models dynamically from Mistral's API
      const modelsResponse = await fetch('/api/mistral/models', {
        method: 'GET',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        }
      })

      let models = []
      
      if (modelsResponse.ok) {
        const modelsData = await modelsResponse.json()
        models = modelsData.data?.map(model => {
          const conceptionDate = this.parseModelDate(model, 'mistral')
          console.log('üîç Mistral model:', model.id, 'Raw model data:', model, 'Parsed conception date:', conceptionDate)
          return {
            id: model.id,
            name: model.id,
            contextSize: model.context_window || null,
            costPer1k: model.pricing?.input_cost_per_1k_tokens || null,
            capabilities: model.capabilities || [],
            description: model.description || null,
            conceptionDate: conceptionDate
          }
        }) || []
      } else {
        // Return empty array if models endpoint fails - no hardcoded fallback
        console.log('‚ö†Ô∏è Models endpoint failed, no models available')
        models = []
      }

      console.log(`‚úÖ Mistral validation successful - ${models.length} models available`)
      
      return {
        success: true,
        models,
        service: 'mistral'
      }
    } catch (error) {
      console.error('‚ùå Mistral validation failed:', error)
      
      // If the error is a network error or CORS, try fallback validation
      if (error.message.includes('Failed to fetch') || error.message.includes('CORS')) {
        console.log('üîÑ Trying fallback validation for Mistral...')
        
        // Return success with hardcoded models for CORS issues
        // No hardcoded fallback models allowed
        const fallbackModels = []
        
        console.log('‚úÖ Mistral fallback validation successful')
        return {
          success: true,
          models: fallbackModels,
          service: 'mistral',
          warning: 'API validation skipped due to CORS restrictions'
        }
      }
      
      return {
        success: false,
        error: error.message,
        models: []
      }
    }
  }

  // All Mistral hardcoded functions removed - only dynamic data allowed

  // Perplexity API validation
  async validatePerplexity(apiKey) {
    try {
      console.log('üîç Validating Perplexity API key...')
      console.log('üîç Using API key:', apiKey ? `${apiKey.substring(0, 10)}...` : 'undefined')
      
      // Perplexity doesn't have a models endpoint, test with completion using known model
      const response = await fetch('/api/perplexity/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: 'sonar-pro',
          messages: [{ role: 'user', content: 'Hello' }],
          max_tokens: 5,
          temperature: 0.1
        })
      })

      console.log('üîç Perplexity response status:', response.status, response.statusText)
      
      if (!response.ok) {
        const errorText = await response.text()
        console.error('‚ùå Perplexity API error response:', errorText)
        throw new Error(`HTTP ${response.status}: ${response.statusText}`)
      }

      // Perplexity doesn't provide models endpoint, return empty array
      const models = []

      console.log(`‚úÖ Perplexity validation successful - API key is valid`)
      
      return {
        success: true,
        models,
        service: 'perplexity'
      }
    } catch (error) {
      console.error('‚ùå Perplexity validation failed:', error)
      return {
        success: false,
        error: error.message,
        models: []
      }
    }
  }

  // Hugging Face API validation
  async validateHuggingFace(apiKey) {
    try {
      console.log('üîç Validating Hugging Face API key...')
      console.log('üîç Using API key:', apiKey ? `${apiKey.substring(0, 10)}...` : 'undefined')
      
      // Fetch available Stable Diffusion models
      const modelsResponse = await fetch('/api/huggingface/models', {
        method: 'GET',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        }
      })

      if (!modelsResponse.ok) {
        throw new Error(`HTTP ${modelsResponse.status}: ${modelsResponse.statusText}`)
      }

      const modelsData = await modelsResponse.json()
      const availableModels = modelsData.filter(model => 
        model.id && model.id.includes('stable-diffusion')
      )
      
      if (availableModels.length === 0) {
        throw new Error('No Stable Diffusion models available')
      }

      // Test with first available model
      const testModel = availableModels[0].id
      console.log('üîç Testing with model:', testModel)
      
      const response = await fetch(`/api/huggingface/models/${testModel}`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          inputs: 'a simple test image',
          parameters: {
            max_new_tokens: 1
          }
        })
      })

      console.log('üîç Hugging Face response status:', response.status, response.statusText)
      
      if (!response.ok) {
        const errorText = await response.text()
        console.error('‚ùå Hugging Face API error response:', errorText)
        throw new Error(`HTTP ${response.status}: ${response.statusText}`)
      }

      const models = availableModels.map(model => ({
        id: model.id,
        name: model.id.split('/').pop(),
        description: model.description || 'Stable Diffusion model'
      }))

      console.log(`‚úÖ Hugging Face validation successful - ${models.length} models available`)
      
      return {
        success: true,
        models,
        service: 'huggingface'
      }
    } catch (error) {
      console.error('‚ùå Hugging Face validation failed:', error)
      return {
        success: false,
        error: error.message,
        models: []
      }
    }
  }

  // Stability AI API validation
  async validateStabilityAI(apiKey) {
    try {
      console.log('üîç Validating Stability AI API key...')
      console.log('üîç Using API key:', apiKey ? `${apiKey.substring(0, 10)}...` : 'undefined')
      
      // Stability AI doesn't have models endpoint, test with image generation
      const response = await fetch('/api/stability/generation/stable-diffusion-xl-1024-v1-0/text-to-image', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          text_prompts: [{ text: 'a simple test image' }],
          cfg_scale: 7,
          height: 1024,
          width: 1024,
          samples: 1,
          steps: 10
        })
      })

      console.log('üîç Stability AI response status:', response.status, response.statusText)
      
      if (!response.ok) {
        const errorText = await response.text()
        console.error('‚ùå Stability AI API error response:', errorText)
        throw new Error(`HTTP ${response.status}: ${response.statusText}`)
      }

      // Stability AI has known models
      const models = [
        {
          id: 'stable-diffusion-xl-1024-v1-0',
          name: 'Stable Diffusion XL',
          description: 'High-quality image generation model'
        },
        {
          id: 'stable-diffusion-v1-6',
          name: 'Stable Diffusion v1.6',
          description: 'Standard image generation model'
        },
        {
          id: 'stable-diffusion-v2-1',
          name: 'Stable Diffusion v2.1',
          description: 'Enhanced image generation model'
        }
      ]

      console.log(`‚úÖ Stability AI validation successful - API key is valid`)
      
      return {
        success: true,
        models,
        service: 'stability'
      }
    } catch (error) {
      console.error('‚ùå Stability AI validation failed:', error)
      return {
        success: false,
        error: error.message,
        models: []
      }
    }
  }

  // Craiyon API validation
  async validateCraiyon(apiKey) {
    try {
      console.log('üîç Validating Craiyon API key...')
      console.log('üîç Using API key:', apiKey ? `${apiKey.substring(0, 10)}...` : 'undefined')
      
      // Craiyon doesn't have models endpoint, test with completion
      const response = await fetch('/api/craiyon/v3', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          prompt: 'a simple test image',
          model: 'art',
          negative_prompt: '',
          token: apiKey || 'free'
        })
      })

      console.log('üîç Craiyon response status:', response.status, response.statusText)
      
      if (!response.ok) {
        const errorText = await response.text()
        console.error('‚ùå Craiyon API error response:', errorText)
        throw new Error(`HTTP ${response.status}: ${response.statusText}`)
      }

      // Craiyon has only one model
      const models = [{
        id: 'craiyon-art',
        name: 'Craiyon Art',
        description: 'Free AI image generation model'
      }]

      console.log(`‚úÖ Craiyon validation successful - API is working`)
      
      return {
        success: true,
        models,
        service: 'craiyon'
      }
    } catch (error) {
      console.error('‚ùå Craiyon validation failed:', error)
      return {
        success: false,
        error: error.message,
        models: []
      }
    }
  }

  // ModelsLab API validation
  async validateModelsLab(apiKey) {
    try {
      console.log('üîç Validating ModelsLab API key...')
      console.log('üîç Using API key:', apiKey ? `${apiKey.substring(0, 10)}...` : 'undefined')
      
      // Test with text-to-image generation
      const response = await fetch('/api/modelslab/v6/realtime/text2img', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          key: apiKey,
          prompt: 'a simple test image',
          negative_prompt: '',
          width: 512,
          height: 512,
          samples: 1,
          num_inference_steps: 20,
          safety_tolerance: 2
        })
      })

      console.log('üîç ModelsLab response status:', response.status, response.statusText)
      
      if (!response.ok) {
        const errorText = await response.text()
        console.error('‚ùå ModelsLab API error response:', errorText)
        throw new Error(`HTTP ${response.status}: ${response.statusText}`)
      }

      // ModelsLab has multiple models
      const models = [
        {
          id: 'modelslab-stable-diffusion',
          name: 'Stable Diffusion',
          description: 'High-quality image generation model'
        },
        {
          id: 'modelslab-realistic',
          name: 'Realistic Vision',
          description: 'Photorealistic image generation'
        },
        {
          id: 'modelslab-anime',
          name: 'Anime Style',
          description: 'Anime-style image generation'
        }
      ]

      console.log(`‚úÖ ModelsLab validation successful - API key is valid`)
      
      return {
        success: true,
        models,
        service: 'modelslab'
      }
    } catch (error) {
      console.error('‚ùå ModelsLab validation failed:', error)
      return {
        success: false,
        error: error.message,
        models: []
      }
    }
  }

  // Cohere API validation
  async validateCohere(apiKey) {
    try {
      console.log('üîç Validating Cohere API key...')
      
      const response = await fetch('/api/cohere/models', {
        method: 'GET',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        }
      })

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`)
      }

      const data = await response.json()
      
      const models = data.models.map(model => ({
        id: model.name,
        name: model.name,
        contextSize: model.context_window || null,
        costPer1k: model.pricing?.input_cost_per_1k_tokens || null,
        capabilities: model.capabilities || [],
        description: model.description || null
      })).sort((a, b) => a.name.localeCompare(b.name))

      console.log(`‚úÖ Cohere validation successful - ${models.length} models found`)
      
      return {
        success: true,
        models,
        service: 'cohere'
      }
    } catch (error) {
      console.error('‚ùå Cohere validation failed:', error)
      return {
        success: false,
        error: error.message,
        models: []
      }
    }
  }

  // GROK API validation (xAI)
  async validateGrok(apiKey) {
    try {
      console.log('üîç Validating GROK API key...')
      
      const response = await fetch('/api/grok/models', {
        method: 'GET',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        }
      })

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`)
      }

      const data = await response.json()
      
      const models = data.data.map(model => ({
        id: model.id,
        name: model.id,
        contextSize: model.context_window || null,
        costPer1k: model.pricing?.input_cost_per_1k_tokens || null,
        capabilities: model.capabilities || [],
        description: model.description || null
      })).sort((a, b) => a.name.localeCompare(b.name))

      console.log(`‚úÖ GROK validation successful - ${models.length} models found`)
      
      return {
        success: true,
        models,
        service: 'grok'
      }
    } catch (error) {
      console.error('‚ùå GROK validation failed:', error)
      return {
        success: false,
        error: error.message,
        models: []
      }
    }
  }

  // Stable Diffusion API validation
  async validateStableDiffusion(apiKey) {
    try {
      console.log('üîç Validating Stable Diffusion API key...')
      
      // Validate with Stability AI API
      const response = await fetch('/api/stability/generation/stable-diffusion-xl-1024-v1-0/text-to-image', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          text_prompts: [{ text: 'test' }],
          cfg_scale: 7,
          height: 1024,
          width: 1024,
          samples: 1,
          steps: 30
        })
      })

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`)
      }

      // No hardcoded models allowed - return empty array
      const models = []

      console.log(`‚úÖ Stable Diffusion validation successful - ${models.length} models found`)
      
      return {
        success: true,
        models,
        service: 'stable_diffusion'
      }
    } catch (error) {
      console.error('‚ùå Stable Diffusion validation failed:', error)
      return {
        success: false,
        error: error.message,
        models: []
      }
    }
  }

  // ElevenLabs API validation
  async validateElevenLabs(apiKey) {
    try {
      console.log('üîç Validating ElevenLabs API key...')
      
      // Validate with ElevenLabs API
      const response = await fetch('/api/elevenlabs/v1/voices', {
        method: 'GET',
        headers: {
          'xi-api-key': apiKey,
          'Content-Type': 'application/json'
        }
      })

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`)
      }

      const data = await response.json()
      
      const models = data.voices?.map(voice => ({
        id: voice.voice_id,
        name: voice.name,
        contextSize: null,
        costPer1k: voice.pricing?.cost_per_1k_characters || null,
        capabilities: voice.capabilities || [],
        description: voice.description || null
      })) || []

      console.log(`‚úÖ ElevenLabs validation successful - ${models.length} models found`)
      
      return {
        success: true,
        models,
        service: 'elevenlabs'
      }
    } catch (error) {
      console.error('‚ùå ElevenLabs validation failed:', error)
      return {
        success: false,
        error: error.message,
        models: []
      }
    }
  }

  // Main validation method
  async validateApiKey(service, apiKey) {
    if (!apiKey || apiKey.length < 10) {
      return {
        success: false,
        error: 'Invalid API key format',
        models: []
      }
    }

    // Check cache first
    const cacheKey = `${service}_${apiKey.slice(-8)}`
    if (this.validationCache.has(cacheKey)) {
      console.log(`üìã Using cached validation for ${service}`)
      return this.validationCache.get(cacheKey)
    }

    let result
    switch (service) {
      case 'openai':
        result = await this.validateOpenAI(apiKey)
        break
      case 'claude':
        result = await this.validateClaude(apiKey)
        break
      case 'gemini':
        result = await this.validateGemini(apiKey)
        break
      case 'mistral':
        result = await this.validateMistral(apiKey)
        break
      case 'perplexity':
        result = await this.validatePerplexity(apiKey)
        break
      case 'cohere':
        result = await this.validateCohere(apiKey)
        break
      case 'grok':
        result = await this.validateGrok(apiKey)
        break
      case 'stable_diffusion':
        result = await this.validateStableDiffusion(apiKey)
        break
      case 'elevenlabs':
        result = await this.validateElevenLabs(apiKey)
        break
      case 'huggingface':
        result = await this.validateHuggingFace(apiKey)
        break
      case 'stability':
      case 'stabilityai':
        result = await this.validateStabilityAI(apiKey)
        break
      case 'craiyon':
        result = await this.validateCraiyon(apiKey)
        break
      case 'modelslab':
        result = await this.validateModelsLab(apiKey)
        break
      default:
        result = {
          success: false,
          error: 'Unsupported service',
          models: []
        }
    }

    // Cache successful results for 5 minutes
    if (result.success) {
      this.validationCache.set(cacheKey, result)
      setTimeout(() => this.validationCache.delete(cacheKey), 5 * 60 * 1000)
    }

    return result
  }

  // Get capability color
  getCapabilityColor(capability) {
    const colors = {
      'thinking': 'bg-purple-100 text-purple-800 dark:bg-purple-900 dark:text-purple-200',
      'coding': 'bg-green-100 text-green-800 dark:bg-green-900 dark:text-green-200',
      'writing': 'bg-blue-100 text-blue-800 dark:bg-blue-900 dark:text-blue-200',
      'image': 'bg-pink-100 text-pink-800 dark:bg-pink-900 dark:text-pink-200',
      'audio': 'bg-yellow-100 text-yellow-800 dark:bg-yellow-900 dark:text-yellow-200'
    }
    return colors[capability] || 'bg-gray-100 text-gray-800 dark:bg-gray-900 dark:text-gray-200'
  }
}

export const aiValidationService = new AIValidationService()
